{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "baf6f0e4-d9a0-4fbb-b8e7-c2648d23140b",
    "_uuid": "3b7be88b-02e1-4120-a9cf-e8b2ca1b35d1",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 1. Environment Setup and Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "26b6dde6-e9c3-4af9-97f5-c80853ad6c5f",
    "_uuid": "96a251d1-1e87-4fa8-b5f1-a1c0c0601a50",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:11.648588Z",
     "iopub.status.busy": "2025-11-27T08:53:11.648229Z",
     "iopub.status.idle": "2025-11-27T08:53:21.340457Z",
     "shell.execute_reply": "2025-11-27T08:53:21.339541Z",
     "shell.execute_reply.started": "2025-11-27T08:53:11.648565Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Cannot install spacy-transformers==1.3.4 and transformers==4.39.3 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m357.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \\\n",
    "  spacy==3.7.4 \\\n",
    "  spacy-transformers==1.3.4 \\\n",
    "  \"transformers==4.39.3\" \\\n",
    "  \"tokenizers==0.15.2\" \\\n",
    "  \"datasets==2.21.0\" \\\n",
    "  \"tqdm==4.66.5\" \\\n",
    "  \"nltk==3.9.1\" \\\n",
    "  \"scikit-learn==1.5.2\" \\\n",
    "  \"numpy==1.26.4\"\n",
    "%pip install -q --no-cache-dir \\\n",
    "  https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.7.3/en_core_web_trf-3.7.3-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ee795b5f-5edd-4d43-8378-d478e905f37e",
    "_uuid": "621f864d-bc12-45aa-aa26-4441c153cdc1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:27.740254Z",
     "iopub.status.busy": "2025-11-27T08:53:27.739964Z",
     "iopub.status.idle": "2025-11-27T08:53:27.750766Z",
     "shell.execute_reply": "2025-11-27T08:53:27.749769Z",
     "shell.execute_reply.started": "2025-11-27T08:53:27.740231Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup completed!\n",
      "CUDA available: True\n",
      "GPU: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /usr/share/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.chunk.regexp import RegexpParser\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import warnings\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from functools import lru_cache\n",
    "from transformers import AutoModel\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "print(\"Environment setup completed!\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3fc7633-9a85-4043-a90a-f3538ded36d8",
    "_uuid": "a82bdfec-38e6-4336-8fde-2f9fd6a3b328",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 2. Model and Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "724e89c0-4fe8-480e-b5c4-4c8e49c35c39",
    "_uuid": "f6ffc71a-7bb1-4d5d-bd37-7f92354f5079",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:27.751940Z",
     "iopub.status.busy": "2025-11-27T08:53:27.751700Z",
     "iopub.status.idle": "2025-11-27T08:53:29.992985Z",
     "shell.execute_reply": "2025-11-27T08:53:29.992225Z",
     "shell.execute_reply.started": "2025-11-27T08:53:27.751921Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Inspec dataset...\n",
      "Combined dataset size: 2000 documents\n",
      "Sample document structure:\n",
      "dict_keys(['id', 'title', 'abstract', 'keyphrases', 'prmu'])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "MODEL_NAME = 'allenai/scibert_scivocab_uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "model.eval()\n",
    "print(\"Loading Inspec dataset...\")\n",
    "dataset = load_dataset(\"taln-ls2n/inspec\",trust_remote_code = True)\n",
    "combined_dataset = concatenate_datasets([\n",
    "    dataset['train'],\n",
    "    dataset['validation'], \n",
    "    dataset['test']\n",
    "])\n",
    "print(f\"Combined dataset size: {len(combined_dataset)} documents\")\n",
    "print(\"Sample document structure:\")\n",
    "print(combined_dataset[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:29.994153Z",
     "iopub.status.busy": "2025-11-27T08:53:29.993881Z",
     "iopub.status.idle": "2025-11-27T08:53:29.999817Z",
     "shell.execute_reply": "2025-11-27T08:53:29.999114Z",
     "shell.execute_reply.started": "2025-11-27T08:53:29.994128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_phrase(phrase):\n",
    "    if not phrase: return \"\"\n",
    "    return \" \".join([stemmer.stem(w) for w in phrase.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "def14c50-b8df-465d-9b3c-721af5f417d6",
    "_uuid": "89add2ae-620c-45ec-87fe-9e9ad1bf7cd8",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 3. Core Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c40280ec-cea4-4732-8dd2-427ae72357df",
    "_uuid": "009fbbd9-1cd0-4d44-b629-cce5e0d3c60c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:30.000984Z",
     "iopub.status.busy": "2025-11-27T08:53:30.000735Z",
     "iopub.status.idle": "2025-11-27T08:53:30.021930Z",
     "shell.execute_reply": "2025-11-27T08:53:30.021027Z",
     "shell.execute_reply.started": "2025-11-27T08:53:30.000961Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import RegexpParser\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN \n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = re.sub(r'[^\\w\\s.,;:!?()-]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07669a75-b9cf-4f87-ac05-1f351a3c5482",
    "_uuid": "fdffbede-e674-4a84-8623-8300068c8a09",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 4. Candidate Phrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "93532bb5-c7f0-4f95-af92-26883b42c636",
    "_uuid": "0fb56090-ff00-48c5-a247-5fc0094ca25e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:30.023181Z",
     "iopub.status.busy": "2025-11-27T08:53:30.022898Z",
     "iopub.status.idle": "2025-11-27T08:53:30.049757Z",
     "shell.execute_reply": "2025-11-27T08:53:30.048830Z",
     "shell.execute_reply.started": "2025-11-27T08:53:30.023157Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teks Asli: Machine learning algorithms are powerful computational methods for data analysis. The machine learning algorithm performed well.\n",
      "\n",
      "Hasil Ekstraksi Kandidat (Deduplikasi Lemma & Bentuk Terpanjang):\n",
      "1. 'machine learning algorithms' (Posisi: 0, Panjang: 3)\n",
      "2. 'powerful computational methods' (Posisi: 32, Panjang: 3)\n",
      "3. 'data analysis' (Posisi: 67, Panjang: 2)\n",
      "4. 'machine' (Posisi: 0, Panjang: 1)\n",
      "5. 'algorithm' (Posisi: 17, Panjang: 1)\n"
     ]
    }
   ],
   "source": [
    "def extract_candidate_phrases(text, min_length=1, max_length=5):\n",
    "    text = preprocess_text(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    grammar = \"\"\"  NP:\n",
    "        {<NN.*|JJ>*<NN.*>}  # Adjective(s)(optional) + Noun(s)\"\"\"\n",
    "    cp = RegexpParser(grammar)\n",
    "    tree = cp.parse(pos_tags)\n",
    "    candidates = {}\n",
    "    current_char_index = 0\n",
    "    for subtree in tree:\n",
    "        if hasattr(subtree, 'label') and subtree.label() == 'NP':\n",
    "            chunk_leaves = subtree.leaves()\n",
    "            if not (min_length <= len(chunk_leaves) <= max_length):\n",
    "                continue\n",
    "            surface_tokens = [w for w, t in chunk_leaves]\n",
    "            surface_form = \" \".join(surface_tokens)\n",
    "            lemma_tokens = []\n",
    "            for word, tag in chunk_leaves:\n",
    "                wn_tag = get_wordnet_pos(tag)\n",
    "                lemma_tokens.append(lemmatizer.lemmatize(word, wn_tag))\n",
    "            \n",
    "            lemma_form = \" \".join(lemma_tokens)\n",
    "            if (lemma_tokens[0] in stop_words or \n",
    "                lemma_tokens[-1] in stop_words):\n",
    "                continue\n",
    "            start_idx = text.find(surface_form)\n",
    "            if lemma_form not in candidates:\n",
    "                candidates[lemma_form] = {\n",
    "                    'phrase': surface_form,       \n",
    "                    'position': start_idx,       \n",
    "                    'length': len(surface_tokens)\n",
    "                }\n",
    "            else:\n",
    "                existing = candidates[lemma_form]\n",
    "                if len(surface_form) > len(existing['phrase']):\n",
    "                    existing['phrase'] = surface_form\n",
    "                if start_idx != -1 and start_idx < existing['position']:\n",
    "                    existing['position'] = start_idx\n",
    "\n",
    "    return list(candidates.values())\n",
    "\n",
    "sample_text = \"Machine learning algorithms are powerful computational methods for data analysis. The machine learning algorithm performed well.\"\n",
    "test_candidates = extract_candidate_phrases(sample_text)\n",
    "\n",
    "print(f\"Teks Asli: {sample_text}\\n\")\n",
    "print(\"Hasil Ekstraksi Kandidat\")\n",
    "for i, candidate in enumerate(test_candidates):\n",
    "    print(f\"{i+1}. '{candidate['phrase']}' (Posisi: {candidate['position']}, Panjang: {candidate['length']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b847ff25-a48c-450a-ae42-5bbe33b52db6",
    "_uuid": "17a62dd1-b8ce-4299-8fec-2542447bf29e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:30.051180Z",
     "iopub.status.busy": "2025-11-27T08:53:30.050947Z",
     "iopub.status.idle": "2025-11-27T08:53:44.249527Z",
     "shell.execute_reply": "2025-11-27T08:53:44.248677Z",
     "shell.execute_reply.started": "2025-11-27T08:53:30.051162Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Metrics Test (Recall & Precision)...\n",
      "Starting candidate metrics check on 2000 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d95c5c14be42729a7264f90d6ca9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checking Candidates:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Candidate Evaluation Results (Micro-Average) ---\n",
      "Total Unique Ground Truth       : 19243\n",
      "Total Candidates Generated      : 53315\n",
      "Total Match (Correct)           : 11313\n",
      "----------------------------------------\n",
      "Recall Ceiling : 58.79%\n",
      "Precision      : 21.22%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def check_candidate_metrics(dataset, extractor_function, stemmer_function, max_docs=None):\n",
    "    total_ground_truth_count = 0\n",
    "    total_found_in_candidates = 0\n",
    "    total_candidates_generated = 0 \n",
    "    \n",
    "    docs_to_process = dataset\n",
    "    if max_docs is not None:\n",
    "        docs_to_process = dataset.select(range(max_docs))\n",
    "        \n",
    "    print(f\"Starting candidate metrics check on {len(docs_to_process)} documents...\")\n",
    "\n",
    "    for document in tqdm(docs_to_process, desc=\"Checking Candidates\"):\n",
    "        # 1. Get Ground Truth Keyphrases\n",
    "        true_keyphrases = document.get('keyphrases', [])\n",
    "        if not true_keyphrases:\n",
    "            continue\n",
    "        stemmed_true = set(stemmer_function(p) for p in true_keyphrases if p.strip())\n",
    "        total_ground_truth_count += len(stemmed_true)\n",
    "        title = document.get('title', '')\n",
    "        abstract = document.get('abstract', '')\n",
    "        document_text = '. '.join([t for t in [title, abstract] if t.strip()])\n",
    "        \n",
    "        if not document_text:\n",
    "            continue\n",
    "        try:\n",
    "            candidates_list = extractor_function(document_text)\n",
    "            candidate_phrases = [c['phrase'] for c in candidates_list]\n",
    "            stemmed_candidates = set(stemmer_function(p) for p in candidate_phrases if p.strip())\n",
    "            total_candidates_generated += len(stemmed_candidates)\n",
    "            found_phrases = stemmed_true.intersection(stemmed_candidates)\n",
    "            total_found_in_candidates += len(found_phrases)\n",
    "            \n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"⚠️ Error processing document: {e}\")\n",
    "    if total_ground_truth_count == 0:\n",
    "        return 0.0, 0.0\n",
    "        \n",
    "    recall_ceiling = total_found_in_candidates / total_ground_truth_count\n",
    "    \n",
    "    precision = 0.0\n",
    "    if total_candidates_generated > 0:\n",
    "        precision = total_found_in_candidates / total_candidates_generated\n",
    "    \n",
    "    print(\"\\n--- Candidate Evaluation Results (Micro-Average) ---\")\n",
    "    print(f\"Total Unique Ground Truth       : {total_ground_truth_count}\")\n",
    "    print(f\"Total Candidates Generated      : {total_candidates_generated}\")\n",
    "    print(f\"Total Match (Correct)           : {total_found_in_candidates}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Recall Ceiling : {recall_ceiling * 100:.2f}%\")\n",
    "    print(f\"Precision      : {precision * 100:.2f}%\")\n",
    "    \n",
    "    return recall_ceiling, precision\n",
    "recall_val, precision_val = check_candidate_metrics(\n",
    "    combined_dataset, \n",
    "    extract_candidate_phrases,  \n",
    "    stem_phrase,                \n",
    "    max_docs=None               \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc1743e6-c9cf-41fb-b64b-4dfe5403d2e3",
    "_uuid": "ccd51525-4d9a-41a6-8e80-b3c7c64242ca",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 6. Additional Scores Implementation (Theme & Position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b0771e52-fc3f-4a46-9c92-a2577af33c42",
    "_uuid": "17964c69-03cd-4c26-b1b5-b9e32a988872",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:44.251869Z",
     "iopub.status.busy": "2025-11-27T08:53:44.251619Z",
     "iopub.status.idle": "2025-11-27T08:53:44.259499Z",
     "shell.execute_reply": "2025-11-27T08:53:44.258642Z",
     "shell.execute_reply.started": "2025-11-27T08:53:44.251842Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_pooled_embeddings_batched(texts, tokenizer, model, device, BATCH_SIZE=64, pooling_strategy='mean'):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "            for i in range(0, len(texts), BATCH_SIZE):\n",
    "                batch_texts = texts[i : i + BATCH_SIZE]\n",
    "                inputs = tokenizer(\n",
    "                    batch_texts, \n",
    "                    padding='max_length',\n",
    "                    truncation=True, \n",
    "                    max_length=512, \n",
    "                    return_tensors='pt'\n",
    "                ).to(device)\n",
    "                outputs = model(**inputs, output_hidden_states=True)\n",
    "                last_hidden_state = outputs.hidden_states[-2]\n",
    "                attention_mask = inputs['attention_mask']\n",
    "                if pooling_strategy == 'cls':\n",
    "                    pooled_embeddings = last_hidden_state[:, 0, :]\n",
    "                elif pooling_strategy == 'mean':\n",
    "                    mask_expanded = attention_mask.unsqueeze(-1).expand_as(last_hidden_state)\n",
    "                    sum_embeddings = torch.sum(last_hidden_state * mask_expanded, dim=1)\n",
    "                    sum_mask = torch.clamp(attention_mask.sum(dim=1), min=1e-9)\n",
    "                    pooled_embeddings = sum_embeddings / sum_mask.unsqueeze(-1)\n",
    "                all_embeddings.append(pooled_embeddings.cpu().numpy())\n",
    "        \n",
    "    if not all_embeddings:\n",
    "        return np.array([])\n",
    "        \n",
    "    return np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2f1fe0c5-924d-4f96-a50c-8af4c82d81c6",
    "_uuid": "1ffaa59b-8212-4fc4-8096-b18d016ba86a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:44.260842Z",
     "iopub.status.busy": "2025-11-27T08:53:44.260579Z",
     "iopub.status.idle": "2025-11-27T08:53:44.286577Z",
     "shell.execute_reply": "2025-11-27T08:53:44.285703Z",
     "shell.execute_reply.started": "2025-11-27T08:53:44.260824Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fungsi 'calculate_scores_batched' (Cell 21) telah diperbarui.\n",
      "   Global Score sekarang menggunakan Mean Pooling + Cosine Similarity.\n"
     ]
    }
   ],
   "source": [
    "def calculate_scores_batched(document_text, title, candidates, tokenizer, model, device, BATCH_SIZE=64, pooling_strategy='mean'): \n",
    "    # --- 1. Persiapan Teks  ---\n",
    "    original_text = document_text\n",
    "    masked_texts = []\n",
    "    \n",
    "    for c in candidates:\n",
    "        phr = c[\"phrase\"]\n",
    "        n_words = len(phr.split())\n",
    "        mask_seq = \" \".join([\"[MASK]\"] * n_words)\n",
    "        try:\n",
    "            pattern = re.compile(r'\\b' + re.escape(phr) + r'\\b', re.IGNORECASE)\n",
    "            masked_text = pattern.sub(mask_seq, original_text)\n",
    "        except:\n",
    "            masked_text = original_text.replace(phr, mask_seq)\n",
    "            \n",
    "        masked_texts.append(masked_text)\n",
    "\n",
    "    candidate_phrases = [c['phrase'] for c in candidates]\n",
    "\n",
    "    # --- 2. Calculate GLOBAL SCORE  ---\n",
    "    global_scores = {}\n",
    "    try:\n",
    "        texts_for_global_score = [original_text] + masked_texts\n",
    "        all_pooled_embeddings_global = get_pooled_embeddings_batched(\n",
    "            texts_for_global_score, tokenizer, model, device, BATCH_SIZE, pooling_strategy\n",
    "        )\n",
    "        \n",
    "        if all_pooled_embeddings_global.shape[0] > 0:\n",
    "            original_embedding = all_pooled_embeddings_global[0:1]\n",
    "            masked_embeddings = all_pooled_embeddings_global[1:]\n",
    "            \n",
    "            if masked_embeddings.shape[0] > 0:\n",
    "                similarities_global = cosine_similarity(\n",
    "                    masked_embeddings, \n",
    "                    original_embedding\n",
    "                )\n",
    "                global_scores = {\n",
    "                    c['phrase']: (1.0 - sim) \n",
    "                    for c, sim in zip(candidates, similarities_global.flatten())\n",
    "                }\n",
    "            else:\n",
    "                global_scores = {c['phrase']: 0 for c in candidates}\n",
    "        else:\n",
    "             global_scores = {c['phrase']: 0 for c in candidates}\n",
    "            \n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"⚠️ Error in Global Score (CosineSim) calculation: {e}\")\n",
    "        global_scores = {c['phrase']: 0 for c in candidates} # Fallback\n",
    "\n",
    "    # --- 3. Calculate THEME SCORE ---\n",
    "    theme_scores = {}\n",
    "    try:\n",
    "        texts_for_pooling = [title] + candidate_phrases\n",
    "        all_pooled_embeddings = get_pooled_embeddings_batched(\n",
    "            texts_for_pooling, tokenizer, model, device,\n",
    "            BATCH_SIZE=BATCH_SIZE, pooling_strategy='cls'\n",
    "        )\n",
    "    \n",
    "        if all_pooled_embeddings.shape[0] > 0:\n",
    "            title_embedding      = all_pooled_embeddings[0:1]\n",
    "            candidate_embeddings = all_pooled_embeddings[1:]\n",
    "            if candidate_embeddings.shape[0] > 0:\n",
    "                similarities_theme = cosine_similarity(candidate_embeddings, title_embedding)\n",
    "                theme_scores = {c['phrase']: max(0.0, float(sim))\n",
    "                                for c, sim in zip(candidates, similarities_theme.flatten())}\n",
    "            else:\n",
    "                theme_scores = {c['phrase']: 0.0 for c in candidates}\n",
    "        else:\n",
    "            theme_scores = {c['phrase']: 0.0 for c in candidates}\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"⚠️ Error in Theme Score calculation: {e}\")\n",
    "        theme_scores = {c['phrase']: 0.0 for c in candidates}\n",
    "    position_scores = {c['phrase']: 1 / (c['position'] + 1) for c in candidates}\n",
    "    return global_scores, theme_scores, position_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "90dd92c1-84cc-416d-b6e4-3ad1fd1de8e2",
    "_uuid": "6fed11eb-fbb9-4422-9713-a5d72ff45a03",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 7. Reciprocal Rank Fusion (RRF) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "16707898-4c3b-4d37-8c23-af2589f076b1",
    "_uuid": "e868fd48-06ac-4d7b-88e5-ce17a931cb54",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:44.287806Z",
     "iopub.status.busy": "2025-11-27T08:53:44.287476Z",
     "iopub.status.idle": "2025-11-27T08:53:44.310613Z",
     "shell.execute_reply": "2025-11-27T08:53:44.309571Z",
     "shell.execute_reply.started": "2025-11-27T08:53:44.287782Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reciprocal Rank Fusion (RRF) function implemented!\n"
     ]
    }
   ],
   "source": [
    "def reciprocal_rank_fusion(global_scores, theme_scores, position_scores, k=60):\n",
    "    all_phrases = set(global_scores.keys()) | set(theme_scores.keys()) | set(position_scores.keys())\n",
    "    global_ranking = sorted(global_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    theme_ranking = sorted(theme_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    position_ranking = sorted(position_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    global_ranks = {phrase: rank + 1 for rank, (phrase, _) in enumerate(global_ranking)}\n",
    "    theme_ranks = {phrase: rank + 1 for rank, (phrase, _) in enumerate(theme_ranking)}\n",
    "    position_ranks = {phrase: rank + 1 for rank, (phrase, _) in enumerate(position_ranking)}\n",
    "    rrf_scores = {}\n",
    "    for phrase in all_phrases:\n",
    "        rrf_score = 0\n",
    "        if phrase in global_ranks:\n",
    "            rrf_score += 1 / (k + global_ranks[phrase])\n",
    "        if phrase in theme_ranks:\n",
    "            rrf_score += 1 / (k + theme_ranks[phrase])\n",
    "        if phrase in position_ranks:\n",
    "            rrf_score += 1 / (k + position_ranks[phrase])\n",
    "        rrf_scores[phrase] = rrf_score\n",
    "    final_ranking = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [phrase for phrase, score in final_ranking]\n",
    "print(\"Reciprocal Rank Fusion (RRF) function implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c9ecf52-e364-4c5f-9d8d-ec358f880462",
    "_uuid": "78f51b77-f610-4f65-866e-432fc59119e8",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 8. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a0c4b1de-1603-41c5-b3ed-2fd6840496bb",
    "_uuid": "934199ea-f343-402d-acf6-f5a763ca4c3c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:44.311950Z",
     "iopub.status.busy": "2025-11-27T08:53:44.311619Z",
     "iopub.status.idle": "2025-11-27T08:53:44.332931Z",
     "shell.execute_reply": "2025-11-27T08:53:44.332143Z",
     "shell.execute_reply.started": "2025-11-27T08:53:44.311922Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_document(document, tokenizer, model, device):\n",
    "    POOLING_METHOD = 'mean'\n",
    "    title = document.get('title', '') or \"\"\n",
    "    abstract = document.get('abstract', '') or \"\"\n",
    "    keyphrases = document.get('keyphrases', []) or []\n",
    "    raw_text = '. '.join([t for t in [title, abstract] if t.strip()])\n",
    "    if not raw_text or not keyphrases:\n",
    "        return None, None \n",
    "    document_text = preprocess_text(raw_text)\n",
    "    try:\n",
    "        candidates = extract_candidate_phrases(document_text)\n",
    "\n",
    "        if not candidates:\n",
    "            return None, None \n",
    "        global_scores, theme_scores, position_scores = calculate_scores_batched(\n",
    "            document_text, title, candidates, tokenizer, model, device,\n",
    "            pooling_strategy=POOLING_METHOD\n",
    "        )\n",
    "        final_ranking = reciprocal_rank_fusion(global_scores, theme_scores, position_scores, k =40)\n",
    "        evaluation_results = evaluate(final_ranking, keyphrases)\n",
    "        top_15_predictions = final_ranking[:15]\n",
    "        return evaluation_results, top_15_predictions\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"⚠️ Error on document: {e}\")\n",
    "        return None, None # Kembalikan dua None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22c8ad08-ac97-45e4-9302-f3469da82574",
    "_uuid": "f0b90723-a683-40c9-b9a4-112bcd8dd6e6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-27T08:53:44.334388Z",
     "iopub.status.busy": "2025-11-27T08:53:44.333999Z",
     "iopub.status.idle": "2025-11-27T08:53:44.354858Z",
     "shell.execute_reply": "2025-11-27T08:53:44.354049Z",
     "shell.execute_reply.started": "2025-11-27T08:53:44.334363Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample evaluation results:\n",
      "  P@3: 0.667\n",
      "  R@3: 0.667\n",
      "  F1@3: 0.667\n",
      "  P@5: 0.400\n",
      "  R@5: 0.667\n",
      "  F1@5: 0.500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def evaluate(predicted_phrases, true_keyphrases, k_values=[5, 10, 15]):\n",
    "    # 1. Stemming Ground Truth\n",
    "    stemmed_true = set([stem_phrase(phrase) for phrase in true_keyphrases if phrase])\n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        top_k_predicted = predicted_phrases[:k]\n",
    "        stemmed_predicted = set([stem_phrase(phrase) for phrase in top_k_predicted if phrase])\n",
    "        true_positives = len(stemmed_predicted & stemmed_true)\n",
    "        precision = true_positives / len(stemmed_predicted) if len(stemmed_predicted) > 0 else 0\n",
    "        recall = true_positives / len(stemmed_true) if len(stemmed_true) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        results[f'P@{k}'] = precision\n",
    "        results[f'R@{k}'] = recall\n",
    "        results[f'F1@{k}'] = f1\n",
    "    return results\n",
    "\n",
    "test_predicted = ['machine learning', 'data analysis', 'neural networks', 'deep learning', 'artificial intelligence']\n",
    "test_true = ['machine learning', 'data mining', 'neural networks']\n",
    "test_results = evaluate(test_predicted, test_true, [3, 5])\n",
    "print(\"Sample evaluation results:\")\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"  {metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2d08711c-7e4c-464a-b760-012879b108f9",
    "_uuid": "95c1c486-95fa-4704-a06f-a5d0dbe6f1fa",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 9. Main Pipeline Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f22a47b-f804-4e28-92d0-8438cd8ba5d2",
    "_uuid": "f553d4ed-6f6c-4e2d-8d43-a7048e7bd86d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 10. Full Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7cd64e10-3dfb-4f39-80c9-b53c39efe70f",
    "_uuid": "9394558f-a265-4e62-8270-ad28bd975e09",
    "collapsed": false,
    "execution": {
     "execution_failed": "2025-11-27T08:59:43.030Z",
     "iopub.execute_input": "2025-11-27T08:53:44.356531Z",
     "iopub.status.busy": "2025-11-27T08:53:44.355790Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mulai menjalankan evaluasi...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fc97f97be44cd8a0b4cc82fd2b5415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Documents:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def run_full_evaluation(dataset, tokenizer, model, device, max_documents=None):\n",
    "    # 1. Inisialisasi penampung skor\n",
    "    metric_sums = {\n",
    "        'P@5': 0, 'R@5': 0, 'F1@5': 0,\n",
    "        'P@10': 0, 'R@10': 0, 'F1@10': 0,\n",
    "        'P@15': 0, 'R@15': 0, 'F1@15': 0\n",
    "    }\n",
    "    \n",
    "    processed_count = 0\n",
    "    docs_to_process = dataset.select(range(max_documents)) if max_documents is not None else dataset\n",
    "    \n",
    "    # 2. Loop Evaluasi\n",
    "    for document in tqdm(docs_to_process, desc=\"Evaluating Documents\"):\n",
    "        results, _ = process_document(document, tokenizer, model, device)\n",
    "        if results is not None:\n",
    "            for metric, value in results.items():\n",
    "                metric_sums[metric] += value\n",
    "            processed_count += 1\n",
    "            \n",
    "    # 3. Hitung Rata-rata\n",
    "    if processed_count > 0:\n",
    "        average_metrics = {metric: value / processed_count for metric, value in metric_sums.items()}\n",
    "    else:\n",
    "        average_metrics = {metric: 0 for metric in metric_sums.keys()}\n",
    "        \n",
    "    return average_metrics, processed_count\n",
    "TEST_MODE = False  \n",
    "max_docs = 100 if TEST_MODE else None \n",
    "\n",
    "final_results, processed_docs = run_full_evaluation(\n",
    "    combined_dataset, tokenizer, model, device, max_documents=max_docs\n",
    ")\n",
    "\n",
    "\n",
    "for k in [5, 10, 15]:\n",
    "    p = final_results.get(f'P@{k}', 0)\n",
    "    r = final_results.get(f'R@{k}', 0)\n",
    "    f1 = final_results.get(f'F1@{k}', 0)\n",
    "    print(f\"Top-{k:<2} | Precision: {p:.4f} | Recall: {r:.4f} | F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff516202-0e7e-4f14-bec2-c0640d70477b",
    "_uuid": "0fac1c36-ea36-4b36-817d-ad979cfd7210",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 12. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26a75711-79d5-4014-8dc2-b36993360742",
    "_uuid": "e2c45abc-90a4-41f5-8d36-7f81328316a1",
    "collapsed": false,
    "execution": {
     "execution_failed": "2025-11-27T08:59:43.030Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_results(results):\n",
    "    \"\"\"\n",
    "    Create bar plots for evaluation metrics.\n",
    "    \"\"\"\n",
    "    k_values = [5, 10, 15]\n",
    "    precision_values = [results[f'P@{k}'] for k in k_values]\n",
    "    recall_values = [results[f'R@{k}'] for k in k_values]\n",
    "    f1_values = [results[f'F1@{k}'] for k in k_values]\n",
    "    \n",
    "    x = range(len(k_values))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bars1 = ax.bar([i - width for i in x], precision_values, width, label='Precision', alpha=0.8)\n",
    "    bars2 = ax.bar(x, recall_values, width, label='Recall', alpha=0.8)\n",
    "    bars3 = ax.bar([i + width for i in x], f1_values, width, label='F1-Score', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('K Value')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Enhanced MDERank Performance on Inspec Dataset')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'K={k}' for k in k_values])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    def add_value_labels(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                   f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    add_value_labels(bars1)\n",
    "    add_value_labels(bars2)\n",
    "    add_value_labels(bars3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_results(final_results)\n",
    "results_df = pd.DataFrame({\n",
    "    'K': [5, 10, 15],\n",
    "    'Precision': [final_results[f'P@{k}'] for k in [5, 10, 15]],\n",
    "    'Recall': [final_results[f'R@{k}'] for k in [5, 10, 15]],\n",
    "    'F1-Score': [final_results[f'F1@{k}'] for k in [5, 10, 15]]\n",
    "})\n",
    "print(\"\\nResults Summary Table:\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "35e6ed30-3596-4593-848c-567856591d12",
    "_uuid": "724fa4be-abcb-458c-b480-8daa9ed8b8eb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## 13. Analisis Kualitatif Hasil Prediksi\n",
    "#\n",
    "Di bagian ini, kita akan memuat file `.json` yang berisi hasil prediksi\n",
    "dan menganalisisnya secara kualitatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cac48fad-d4e5-4cca-86c2-d98a9ce3273c",
    "_uuid": "09470e45-1b76-4853-823c-34d91d0f1387",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
